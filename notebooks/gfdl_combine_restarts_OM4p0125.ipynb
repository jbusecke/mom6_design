{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mom6_design.postprocessing import combine_mom6_restarts, pad_ice_model, transpose_like_ref, fill_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_mom6_icebergs(file_name):\n",
    "#     datasets = []\n",
    "#     for nrange in [range(0,4), range(4,8), range(8,12), range(12,16)]:\n",
    "#         flist = ['%s.%04i' %(file_name, n) for n in nrange]\n",
    "#         print(flist)\n",
    "#         datasets_sub = [xr.open_mfdataset(file) for file in flist]\n",
    "#         ds_sub = xr.merge(datasets_sub)\n",
    "#         print('###########debug###########')\n",
    "#         print(ds_sub)\n",
    "#         print('###########debug###########')\n",
    "# #         ds_test = xr.open_mfdataset([os.path.join(path, file) for file in flist])\n",
    "        \n",
    "#         datasets.append(ds_sub)\n",
    "# #     out = xr.concat(datasets, dim=concat_dim) \n",
    "#     out = xr.merge(datasets) # not sure why I have to do these seperately to work...\n",
    "#     #This does concat existing dimensions, which is I guess what I want, but it would be nice if there would\n",
    "#     out.attrs['jb_notes'] = 'Combined using xarray by Julius Busecke. See https://github.com/jbusecke/mom6_design for details'\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/archive/Julius.Busecke/model_setups/xanadu_mom6_20181101/OM4p125_IAF_csf_JRA55do1-3_r5_cycle4/archive/restart/20020101'\n",
    "path_iceberg = '/archive/Julius.Busecke/model_setups/xanadu_mom6_20181101/OM4p125_IAF_csf_JRA55do1-3_r5_cycle4/archive_alternative_with_icebergs/hide_from_fre/'\n",
    "# odir = '/archive/Julius.Busecke/model_setups/xanadu_mom6_20181101/OM4p125_IAF_csf_JRA55do1-3_r5_cycle4/archive/restart_combined_experimental/new/'\n",
    "odir = '/archive/Julius.Busecke/model_setups/xanadu_mom6_20181101/OM4p125_IAF_csf_JRA55do1-3_r5_cycle4/archive/restart_combined_final/'\n",
    "refdir = '/archive/Julius.Busecke/model_setups/xanadu_mom6_20181101/OM4p125_IAF_csf_JRA55do1-3_r5_cycle4/archive/'\n",
    "if not os.path.exists(odir):\n",
    "    os.mkdir(odir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The icebergs are all empty?...JRAv1.3 does not include calving\n",
    "ds_icebergs = xr.open_mfdataset('/archive/Julius.Busecke/model_setups/xanadu_mom6_20181101/OM4p125_IAF_csf_JRA55do1-3_r5_cycle4/archive_alternative_with_icebergs/hide_from_fre/icebergs.res.nc.*', drop_variables='i')\n",
    "# print(ds_icebergs)\n",
    "\n",
    "# just rename the first file...since they are all empty anyways...\n",
    "file = '/archive/Julius.Busecke/model_setups/xanadu_mom6_20181101/OM4p125_IAF_csf_JRA55do1-3_r5_cycle4/archive_alternative_with_icebergs/hide_from_fre/icebergs.res.nc.0000'\n",
    "!cp {file} {odir}/icebergs.res.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.780316304 <xarray.Dataset>\n",
      "Dimensions:          (Time: 1, aaxis_1: 1, aaxis_2: 4, xaxis_1: 2880, yaxis_1: 2240, zaxis_1: 6, zaxis_2: 5)\n",
      "Coordinates:\n",
      "  * yaxis_1          (yaxis_1) float64 1.0 2.0 3.0 ... 2.239e+03 2.24e+03\n",
      "  * xaxis_1          (xaxis_1) float64 1.0 2.0 3.0 ... 2.879e+03 2.88e+03\n",
      "  * zaxis_1          (zaxis_1) float64 1.0 2.0 3.0 4.0 5.0 6.0\n",
      "  * zaxis_2          (zaxis_2) float64 1.0 2.0 3.0 4.0 5.0\n",
      "  * aaxis_1          (aaxis_1) float64 1.0\n",
      "  * aaxis_2          (aaxis_2) float64 1.0 2.0 3.0 4.0\n",
      "  * Time             (Time) float64 1.0\n",
      "Data variables:\n",
      "    flux_u           (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    flux_v           (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    flux_t           (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    flux_q           (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    flux_salt        (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    flux_lw          (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    lprec            (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    fprec            (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    runoff           (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    calving          (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    runoff_hflx      (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    calving_hflx     (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    p_surf           (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    flux_sw_vis_dir  (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    flux_sw_vis_dif  (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    flux_sw_nir_dir  (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    flux_sw_nir_dif  (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    part_size        (Time, zaxis_1, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 6, 2240, 2880), chunksize=(1, 1, 2240, 2880)>\n",
      "    h_pond           (Time, zaxis_2, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 5, 2240, 2880), chunksize=(1, 5, 2240, 2880)>\n",
      "    h_snow           (Time, zaxis_2, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 5, 2240, 2880), chunksize=(1, 5, 2240, 2880)>\n",
      "    enth_snow        (Time, aaxis_1, zaxis_2, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 1, 5, 2240, 2880), chunksize=(1, 1, 5, 2240, 2880)>\n",
      "    h_ice            (Time, zaxis_2, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 5, 2240, 2880), chunksize=(1, 5, 2240, 2880)>\n",
      "    H_to_kg_m2       (Time) float64 dask.array<shape=(1,), chunksize=(1,)>\n",
      "    enth_ice         (Time, aaxis_2, zaxis_2, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 4, 5, 2240, 2880), chunksize=(1, 4, 5, 2240, 2880)>\n",
      "    sal_ice          (Time, aaxis_2, zaxis_2, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 4, 5, 2240, 2880), chunksize=(1, 4, 5, 2240, 2880)>\n",
      "    u_ice_C          (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    v_ice_C          (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    str_d            (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    str_t            (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    str_s            (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    rough_mom        (Time, zaxis_1, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 6, 2240, 2880), chunksize=(1, 6, 2240, 2880)>\n",
      "    rough_heat       (Time, zaxis_1, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 6, 2240, 2880), chunksize=(1, 6, 2240, 2880)>\n",
      "    rough_moist      (Time, zaxis_1, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 6, 2240, 2880), chunksize=(1, 6, 2240, 2880)>\n",
      "    coszen           (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    T_skin           (Time, zaxis_2, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 5, 2240, 2880), chunksize=(1, 5, 2240, 2880)>\n",
      "Attributes:\n",
      "    jb_notes:  Combined using xarray by Julius Busecke. See https://github.co...\n",
      "0.619356248 <xarray.Dataset>\n",
      "Dimensions:              (Time: 1, xaxis_1: 2880, yaxis_1: 2240, zaxis_1: 10)\n",
      "Coordinates:\n",
      "  * yaxis_1              (yaxis_1) float64 1.0 2.0 3.0 ... 2.239e+03 2.24e+03\n",
      "  * xaxis_1              (xaxis_1) float64 1.0 2.0 3.0 ... 2.879e+03 2.88e+03\n",
      "  * zaxis_1              (zaxis_1) float64 1.0 2.0 3.0 4.0 ... 7.0 8.0 9.0 10.0\n",
      "  * Time                 (Time) float64 1.0\n",
      "Data variables:\n",
      "    stored_ice           (Time, zaxis_1, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 10, 2240, 2880), chunksize=(1, 10, 2240, 2880)>\n",
      "    stored_heat          (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    iceberg_counter_grd  (Time, yaxis_1, xaxis_1) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "Attributes:\n",
      "    jb_notes:  Combined using xarray by Julius Busecke. See https://github.co...\n"
     ]
    }
   ],
   "source": [
    "# ice model restarts\n",
    "ds_icemodel = combine_mom6_restarts(os.path.join(path, 'ice_model.res.nc'))\n",
    "# icemodel needs special patching (see `discover_debug_ice_model.ipynb`)\n",
    "ds_icemodel = pad_ice_model(ds_icemodel)\n",
    "print(ds_icemodel.nbytes/1e9, ds_icemodel)\n",
    "ds_icemodel.to_netcdf(os.path.join(odir, 'ice_model.res.nc'))\n",
    "\n",
    "# # # calving restart\n",
    "ds_calving = combine_mom6_restarts(os.path.join(path, 'calving.res.nc'))\n",
    "# calving just needs to be padded with zeros\n",
    "ds_calving = fill_missing(ds_calving, 0)\n",
    "print(ds_calving.nbytes/1e9, ds_calving)\n",
    "ds_calving.to_netcdf(os.path.join(odir,'calving.res.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the MOM restart files\n",
    "This takes a long time, but from my tests this did not need any padding? (Or did I forget some step?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOM.res.nc\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (Layer: 75, Time: 1, lath: 2240, lonh: 2880)\n",
      "Coordinates:\n",
      "  * lath     (lath) float64 -83.62 -83.58 -83.54 -83.5 ... 89.86 89.92 89.97\n",
      "  * lonh     (lonh) float64 -298.6 -298.5 -298.4 -298.3 ... 61.05 61.16 61.28\n",
      "  * Layer    (Layer) float64 1.0 3.0 5.0 7.0 ... 3.338e+03 3.591e+03 5.111e+03\n",
      "  * Time     (Time) timedelta64[ns] 90353 days 01:16:18.871345\n",
      "Data variables:\n",
      "    Temp     (Time, Layer, lath, lonh) float64 dask.array<shape=(1, 75, 2240, 2880), chunksize=(1, 75, 2240, 2880)>\n",
      "Attributes:\n",
      "    jb_notes:  Combined using xarray by Julius Busecke. See https://github.co...\n",
      "Filesize: 3.870761568 GB\n",
      "Writing File\n",
      "MOM.res_1.nc\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (Layer: 75, Time: 1, lath: 2240, lonh: 2880)\n",
      "Coordinates:\n",
      "  * lath     (lath) float64 -83.62 -83.58 -83.54 -83.5 ... 89.86 89.92 89.97\n",
      "  * lonh     (lonh) float64 -298.6 -298.5 -298.4 -298.3 ... 61.05 61.16 61.28\n",
      "  * Layer    (Layer) float64 1.0 3.0 5.0 7.0 ... 3.338e+03 3.591e+03 5.111e+03\n",
      "  * Time     (Time) timedelta64[ns] 90353 days 01:16:18.871345\n",
      "Data variables:\n",
      "    Salt     (Time, Layer, lath, lonh) float64 dask.array<shape=(1, 75, 2240, 2880), chunksize=(1, 75, 2240, 2880)>\n",
      "Attributes:\n",
      "    jb_notes:  Combined using xarray by Julius Busecke. See https://github.co...\n",
      "Filesize: 3.870761568 GB\n",
      "Writing File\n",
      "MOM.res_2.nc\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (Layer: 75, Time: 1, lath: 2240, lonh: 2880)\n",
      "Coordinates:\n",
      "  * lath     (lath) float64 -83.62 -83.58 -83.54 -83.5 ... 89.86 89.92 89.97\n",
      "  * lonh     (lonh) float64 -298.6 -298.5 -298.4 -298.3 ... 61.05 61.16 61.28\n",
      "  * Layer    (Layer) float64 1.0 3.0 5.0 7.0 ... 3.338e+03 3.591e+03 5.111e+03\n",
      "  * Time     (Time) timedelta64[ns] 90353 days 01:16:18.871345\n",
      "Data variables:\n",
      "    h        (Time, Layer, lath, lonh) float64 dask.array<shape=(1, 75, 2240, 2880), chunksize=(1, 75, 2240, 2880)>\n",
      "Attributes:\n",
      "    jb_notes:  Combined using xarray by Julius Busecke. See https://github.co...\n",
      "Filesize: 3.870761568 GB\n",
      "Writing File\n",
      "MOM.res_3.nc\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (Layer: 75, Time: 1, lath: 2240, lonq: 2880)\n",
      "Coordinates:\n",
      "  * lath     (lath) float64 -83.62 -83.58 -83.54 -83.5 ... 89.86 89.92 89.97\n",
      "  * lonq     (lonq) float64 -298.5 -298.4 -298.3 -298.2 ... 61.12 61.23 61.35\n",
      "  * Layer    (Layer) float64 1.0 3.0 5.0 7.0 ... 3.338e+03 3.591e+03 5.111e+03\n",
      "  * Time     (Time) timedelta64[ns] 90353 days 01:16:18.871345\n",
      "Data variables:\n",
      "    u        (Time, Layer, lath, lonq) float64 dask.array<shape=(1, 75, 2240, 2880), chunksize=(1, 75, 2240, 2880)>\n",
      "Attributes:\n",
      "    jb_notes:  Combined using xarray by Julius Busecke. See https://github.co...\n",
      "Filesize: 3.870761568 GB\n",
      "Writing File\n",
      "MOM.res_4.nc\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (Layer: 75, Time: 1, lath: 2240, latq: 2240, lonh: 2880)\n",
      "Coordinates:\n",
      "  * lath     (lath) float64 -83.62 -83.58 -83.54 -83.5 ... 89.86 89.92 89.97\n",
      "  * latq     (latq) float64 -83.6 -83.56 -83.52 -83.48 ... 89.89 89.95 90.0\n",
      "  * lonh     (lonh) float64 -298.6 -298.5 -298.4 -298.3 ... 61.05 61.16 61.28\n",
      "  * Layer    (Layer) float64 1.0 3.0 5.0 7.0 ... 3.338e+03 3.591e+03 5.111e+03\n",
      "  * Time     (Time) timedelta64[ns] 90353 days 01:16:18.871345\n",
      "Data variables:\n",
      "    v        (Time, Layer, latq, lonh) float64 dask.array<shape=(1, 75, 2240, 2880), chunksize=(1, 75, 2240, 2880)>\n",
      "    frazil   (Time, lath, lonh) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    ave_ssh  (Time, lath, lonh) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "    m_to_Z   (Time) float64 dask.array<shape=(1,), chunksize=(1,)>\n",
      "    m_to_H   (Time) float64 dask.array<shape=(1,), chunksize=(1,)>\n",
      "    sfc      (Time, lath, lonh) float64 dask.array<shape=(1, 2240, 2880), chunksize=(1, 2240, 2880)>\n",
      "Attributes:\n",
      "    jb_notes:  Combined using xarray by Julius Busecke. See https://github.co...\n",
      "Filesize: 4.025608304 GB\n",
      "Writing File\n"
     ]
    }
   ],
   "source": [
    "# MOM restarts (these need a slight bit more TLC)\n",
    "for filename in ['MOM.res.nc']+['MOM.res_%i.nc' %i for i in range(1,17)]:\n",
    "    print(filename)\n",
    "    ds_mom = combine_mom6_restarts(os.path.join(path, filename))\n",
    "    print(ds_mom)\n",
    "    \n",
    "    #this allows datasets with different x dimensions to be logically merged? \n",
    "    print('Filesize: %s GB' %str(ds_mom.nbytes/1e9))\n",
    "    if ds_mom.nbytes/1e9 > 5.0:\n",
    "        print('Something is kaput')\n",
    "        break\n",
    "        \n",
    "    print('Writing File')\n",
    "    ds_mom.to_netcdf(os.path.join(odir, filename))\n",
    "    del ds_mom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if those restarts work right out of the box with my discover setup... otherwise use [FRE-nctools](https://github.com/NOAA-GFDL/FRE-NCtools) as suggeste [here](https://github.com/NOAA-GFDL/MOM6/issues/958)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC the output files\n",
    "I am having trouble in particular with the ice...model crashed due to icebergs being born on land.\n",
    "This is due to very high values on land!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_check_calving = xr.open_mfdataset(os.path.join(odir,'calving.res.nc'))\n",
    "ds_check_calving.stored_ice.where(ds_check_calving.stored_ice>0).plot(col='zaxis_1', col_wrap=3, robust=True)\n",
    "\n",
    "plt.figure()\n",
    "ds_check_calving.stored_heat.plot(col='zaxis_1', col_wrap=3, robust=True)\n",
    "\n",
    "plt.figure()\n",
    "ds_check_calving.iceberg_counter_grd.plot(robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_check_icemodel = xr.open_mfdataset(os.path.join(odir,'ice_model.res.nc'))\n",
    "ds_check_icemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_check_icemodel.runoff_hflx.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mask out all necessary files\n",
    "\n",
    "This is old. Delete once the refactored merging above is successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ocean mask...\n",
    "griddir = '/archive/Julius.Busecke/model_setups/xanadu_mom6_20181101/OM4p125_IAF_csf_JRA55do1-3_r5_cycle4/input_files/grid/untarred/'\n",
    "mask = xr.open_dataset(os.path.join(griddir, 'ocean_mask.nc'))\n",
    "print(mask)\n",
    "mask.mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert dimensions of mask to calving file\n",
    "# mask_ocean = mask.mask.rename({'nx':'xaxis_1', 'ny':'yaxis_1'})\n",
    "# ds_check_calving.stored_ice.isel(zaxis_1=0).where(mask_ocean==0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_calving_padded = ds_check_calving.where(mask_ocean).fillna(0)\n",
    "ds_calving_padded.stored_ice.isel(zaxis_1=0).where(mask_ocean==0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_icemodel_padded = ds_check_icemodel.where(mask_ocean).fillna(0)\n",
    "# ds_icemodel_padded.calving_hflx.where(mask_ocean==0).plot()\n",
    "# ds_icemodel_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_icemodel_padded.to_netcdf(os.path.join(odir, 'ice_model.res.nc.padded'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_calving_padded.to_netcdf(os.path.join(odir, 'calving.res.nc.padded'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.open_dataset(os.path.join(odir, 'ice_model.res.nc.padded'))#.where(mask_ocean==0)\n",
    "# test.coszen.plot(robust=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.h_ice.plot(robust=True, col='zaxis_2', vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.part_size.sum('zaxis_1').plot(vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.part_size.plot(col='zaxis_1', vmin=1, vmax=1.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output visually against the 1 sec output of the rest run\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gfdl_preprocessing]",
   "language": "python",
   "name": "conda-env-gfdl_preprocessing-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
